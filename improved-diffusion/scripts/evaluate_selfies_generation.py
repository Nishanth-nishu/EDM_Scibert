"""
SELFIES Molecular Generation Evaluator (Single-File Version)
-------------------------------------------------------------
Evaluates molecules generated by SELFIES-based models using:
 - Validity
 - Uniqueness
 - Novelty (optionally vs training set)
 - Molecular properties (QED, MW, LogP, TPSA, etc.)
 - Reconstruction accuracy
 - JSON-safe result saving
"""

import argparse
import pandas as pd
import numpy as np
from rdkit import Chem
from rdkit.Chem import AllChem, Descriptors, Crippen, Lipinski, QED
from rdkit import DataStructs
from rdkit import RDLogger
from collections import Counter
import selfies as sf
from tqdm import tqdm
import os
import json
import warnings

# Suppress RDKit and general warnings
RDLogger.DisableLog('rdApp.*')
warnings.filterwarnings('ignore')


class MolecularEvaluatorSingleFile:
    """Evaluation of SELFIES molecular generation using a single results file"""

    def __init__(self, generated_file, train_file=None):
        """
        :param generated_file: Path to generated results file (must contain columns: Generated_SELFIES, Generated_SMILES, Ground_Truth_SELFIES)
        :param train_file: Optional path to training dataset (SELFIES or SMILES). If provided, novelty will be measured vs this set.
        """
        self.generated_file = generated_file
        self.train_file = train_file
        self.generated_data = self.load_generated_data()
        self.training_smiles = None
        if self.train_file:
            self.training_smiles = self.load_training_smiles(self.train_file)

    # -------------------------------------------------------------------------
    # 1. Load dataset
    # -------------------------------------------------------------------------
    def load_generated_data(self):
        """Load generated molecules from file (auto-detect separator and handle malformed lines)"""
        print("Loading generated molecules...")

        # Try reading with tab delimiter first
        df = pd.read_csv(self.generated_file, sep='\t', engine='python', on_bad_lines='skip')

        # Fallback: whitespace-separated file
        if df.shape[1] == 1:
            df = pd.read_csv(self.generated_file, sep='\s+', engine='python', on_bad_lines='skip')

        expected_cols = ['Generated_SELFIES', 'Generated_SMILES', 'Ground_Truth_SELFIES']
        if not all(col in df.columns for col in expected_cols):
            print(f"⚠ Columns found: {df.columns.tolist()}")
            raise ValueError(f"File must contain columns: {expected_cols}")

        print(f"✓ Loaded {len(df)} generated molecules from {self.generated_file}")
        return df

    # -------------------------------------------------------------------------
    # 2. Helper: decode SELFIES safely
    # -------------------------------------------------------------------------
    def decode_selfies(self, selfies_str):
        """Decode SELFIES → SMILES safely"""
        try:
            if selfies_str and selfies_str != '*' and isinstance(selfies_str, str):
                return sf.decoder(selfies_str)
        except Exception:
            return None
        return None

    # -------------------------------------------------------------------------
    # Helper: load training file for novelty comparison
    # -------------------------------------------------------------------------
    def load_training_smiles(self, train_file):
        """
        Load and canonicalize training molecules from a SELFIES or SMILES file.
        Accepts:
         - a tab-separated file with column 'SELFIES' or 'SMILES'
         - a single-column file with one SELFIES/SMILES per line (will try to auto-detect)
        Returns a set of canonical SMILES strings.
        """
        print("\n" + "=" * 60)
        print("Loading training molecules for novelty comparison...")
        print("=" * 60)

        # Try reading with pandas; try tab first, if single-column fallback will be handled
        try:
            df = pd.read_csv(train_file, sep='\t', engine='python', on_bad_lines='skip')
        except Exception:
            # fallback to simple one-per-line read
            df = pd.read_csv(train_file, sep='\s+', header=None, engine='python', on_bad_lines='skip')

        # Determine column containing molecules
        col = None
        if isinstance(df, pd.DataFrame):
            cols = df.columns.tolist()
            if 'SELFIES' in cols:
                col = 'SELFIES'
            elif 'SMILES' in cols:
                col = 'SMILES'
            elif df.shape[1] == 1:
                # single-column file: try to infer if entries look like SELFIES (contain '[') else assume SMILES
                col = df.columns[0]
            else:
                # attempt to find a column with likely SELFIES content
                for c in cols:
                    sample_vals = df[c].dropna().astype(str).head(10).tolist()
                    if any('[' in v for v in sample_vals):
                        col = c
                        break
                if col is None:
                    # as a last resort, use first column
                    col = cols[0]
        else:
            raise ValueError("Unable to read training file into DataFrame.")

        smiles_set = set()
        for s in tqdm(df[col].astype(str), desc="Canonicalizing training molecules", unit="mol"):
            if not isinstance(s, str) or s.strip() == "":
                continue
            original = s.strip()
            try:
                # If looks like SELFIES (contains '['), decode, else treat as SMILES
                if '[' in original and ('SELFIES' in col.upper() or original.count('[') > 0):
                    decoded = None
                    try:
                        decoded = sf.decoder(original)
                    except Exception:
                        decoded = None
                    if not decoded:
                        continue
                    s_smiles = decoded
                else:
                    s_smiles = original

                mol = Chem.MolFromSmiles(s_smiles)
                if mol:
                    can = Chem.MolToSmiles(mol, canonical=True)
                    smiles_set.add(can)
            except Exception:
                continue

        print(f"✓ Loaded {len(smiles_set)} canonical training molecules from {train_file}")
        return smiles_set

    # -------------------------------------------------------------------------
    # 3. Validity
    # -------------------------------------------------------------------------
    def calculate_validity(self):
        print("\n" + "=" * 60)
        print("1. VALIDITY ANALYSIS")
        print("=" * 60)

        valid_mols = []
        invalid_indices = []

        for idx, row in tqdm(self.generated_data.iterrows(), total=len(self.generated_data), desc="Validating", unit="mol"):
            selfies = row['Generated_SELFIES']
            smiles = self.decode_selfies(selfies)
            mol = Chem.MolFromSmiles(smiles) if smiles else None

            if mol:
                valid_mols.append((idx, smiles, mol))
            else:
                invalid_indices.append(idx)

        validity = 100.0 * len(valid_mols) / len(self.generated_data) if len(self.generated_data) > 0 else 0.0
        print(f"✓ Valid molecules: {len(valid_mols)}/{len(self.generated_data)} ({validity:.2f}%)")

        return {'validity': validity, 'n_valid': len(valid_mols),
                'n_total': len(self.generated_data), 'valid_mols': valid_mols}

    # -------------------------------------------------------------------------
    # 4. Uniqueness
    # -------------------------------------------------------------------------
    def calculate_uniqueness(self, valid_mols):
        print("\n" + "=" * 60)
        print("2. UNIQUENESS ANALYSIS")
        print("=" * 60)

        smiles_list = [smiles for _, smiles, _ in valid_mols]
        unique_smiles = set(smiles_list)
        uniqueness = 100.0 * len(unique_smiles) / len(smiles_list) if len(smiles_list) > 0 else 0.0

        print(f"✓ Unique molecules: {len(unique_smiles)}/{len(smiles_list)} ({uniqueness:.2f}%)")
        return {'uniqueness': uniqueness, 'unique_smiles': unique_smiles}

    # -------------------------------------------------------------------------
    # 5. Novelty (vs training set if provided, else vs Ground_Truth_SELFIES)
    # -------------------------------------------------------------------------
    def calculate_novelty(self, unique_smiles):
        print("\n" + "=" * 60)
        if self.training_smiles is not None:
            print("3. NOVELTY ANALYSIS (vs training set)")
        else:
            print("3. NOVELTY ANALYSIS (vs internal Ground Truth)")
        print("=" * 60)

        # Build reference set: training_smiles if provided, otherwise use Ground_Truth_SELFIES column
        reference_smiles = set()
        if self.training_smiles is not None:
            reference_smiles = self.training_smiles
            ref_size = len(reference_smiles)
            print(f"Using training set of {ref_size} canonical molecules as reference for novelty.")
        else:
            # fallback: decode and canonicalize Ground_Truth_SELFIES in generated file
            for s in self.generated_data['Ground_Truth_SELFIES']:
                decoded = self.decode_selfies(s)
                if decoded:
                    mol = Chem.MolFromSmiles(decoded)
                    if mol:
                        reference_smiles.add(Chem.MolToSmiles(mol, canonical=True))
            print(f"Using {len(reference_smiles)} molecules from Ground_Truth_SELFIES as reference for novelty (fallback).")

        novel_mols = []
        valid_count = 0
        for s in unique_smiles:
            try:
                mol = Chem.MolFromSmiles(s)
                if mol:
                    can = Chem.MolToSmiles(mol, canonical=True)
                    valid_count += 1
                    if can not in reference_smiles:
                        novel_mols.append(can)
            except Exception:
                continue

        novelty = 100.0 * len(novel_mols) / valid_count if valid_count > 0 else 0.0
        print(f"✓ Novel molecules: {len(novel_mols)}/{valid_count} ({novelty:.2f}%) (reference size: {len(reference_smiles)})")
        return {'novelty': novelty, 'novel_mols': novel_mols, 'n_reference': len(reference_smiles)}

    # -------------------------------------------------------------------------
    # 6. Molecular Properties
    # -------------------------------------------------------------------------
    def calculate_molecular_properties(self, valid_mols):
        print("\n" + "=" * 60)
        print("4. MOLECULAR PROPERTIES")
        print("=" * 60)

        props = {'molecular_weight': [], 'logp': [], 'num_hba': [],
                 'num_hbd': [], 'num_rotatable_bonds': [], 'tpsa': [],
                 'num_aromatic_rings': [], 'qed': []}

        for _, _, mol in tqdm(valid_mols, desc="Computing properties", unit="mol"):
            try:
                props['molecular_weight'].append(Descriptors.MolWt(mol))
                props['logp'].append(Crippen.MolLogP(mol))
                props['num_hba'].append(Lipinski.NumHAcceptors(mol))
                props['num_hbd'].append(Lipinski.NumHDonors(mol))
                props['num_rotatable_bonds'].append(Lipinski.NumRotatableBonds(mol))
                props['tpsa'].append(Descriptors.TPSA(mol))
                props['num_aromatic_rings'].append(Descriptors.NumAromaticRings(mol))
                props['qed'].append(QED.qed(mol))
            except Exception:
                # skip molecules that cause unexpected RDKit issues
                continue

        print("\nProperty Statistics:")
        for k, v in props.items():
            if len(v) > 0:
                print(f"{k:20s}: {np.mean(v):.2f} ± {np.std(v):.2f}")
            else:
                print(f"{k:20s}: n/a")

        return {'properties': props}

    # -------------------------------------------------------------------------
    # 7. Reconstruction Accuracy
    # -------------------------------------------------------------------------
    def calculate_reconstruction_accuracy(self):
        print("\n" + "=" * 60)
        print("5. RECONSTRUCTION ACCURACY")
        print("=" * 60)

        exact = 0
        similar = 0
        total = len(self.generated_data)

        for _, row in tqdm(self.generated_data.iterrows(), total=total, desc="Computing accuracy", unit="mol"):
            gen_selfies = row['Generated_SELFIES']
            gt_selfies = row['Ground_Truth_SELFIES']
            gen_smiles = self.decode_selfies(gen_selfies)
            gt_smiles = self.decode_selfies(gt_selfies)

            if not gen_smiles or not gt_smiles:
                continue

            mol1, mol2 = Chem.MolFromSmiles(gen_smiles), Chem.MolFromSmiles(gt_smiles)
            if not mol1 or not mol2:
                continue

            # compare canonical SMILES for exact match
            try:
                if Chem.MolToSmiles(mol1, canonical=True) == Chem.MolToSmiles(mol2, canonical=True):
                    exact += 1
            except Exception:
                pass

            try:
                fp1 = AllChem.GetMorganFingerprintAsBitVect(mol1, 2, nBits=2048)
                fp2 = AllChem.GetMorganFingerprintAsBitVect(mol2, 2, nBits=2048)
                sim = DataStructs.TanimotoSimilarity(fp1, fp2)
                if sim > 0.85:
                    similar += 1
            except Exception:
                continue

        print(f"✓ Exact matches: {exact}/{total} ({100*exact/total:.2f}%)")
        print(f"✓ High similarity (>0.85): {similar}/{total} ({100*similar/total:.2f}%)")

        return {'exact': exact, 'similar': similar, 'total': total}

    # -------------------------------------------------------------------------
    # 8. JSON-safe saving
    # -------------------------------------------------------------------------
    def save_json_safe(self, results, output_file):
        """Save results to JSON, converting RDKit and numpy objects"""

        def convert(obj):
            if hasattr(obj, '__class__') and 'Mol' in str(obj.__class__):
                try:
                    return Chem.MolToSmiles(obj)
                except Exception:
                    return None
            elif isinstance(obj, (np.integer, np.int64)):
                return int(obj)
            elif isinstance(obj, (np.floating, np.float64)):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, (set, Counter)):
                return list(obj)
            elif isinstance(obj, dict):
                return {k: convert(v) for k, v in obj.items()}
            elif isinstance(obj, (list, tuple)):
                return [convert(x) for x in obj]
            else:
                return obj

        with open(output_file, 'w') as f:
            json.dump(convert(results), f, indent=2)
        print(f"✓ Results saved to {output_file}")

    # -------------------------------------------------------------------------
    # 9. Run evaluation
    # -------------------------------------------------------------------------
    def run_evaluation(self, output_dir='./evaluation_results'):
        os.makedirs(output_dir, exist_ok=True)
        results = {}

        validity = self.calculate_validity()
        results['validity'] = validity
        if validity['n_valid'] == 0:
            print("❌ No valid molecules found. Exiting.")
            return results

        uniq = self.calculate_uniqueness(validity['valid_mols'])
        results['uniqueness'] = uniq

        novelty = self.calculate_novelty(uniq['unique_smiles'])
        results['novelty'] = novelty

        props = self.calculate_molecular_properties(validity['valid_mols'])
        results['properties'] = props

        recon = self.calculate_reconstruction_accuracy()
        results['reconstruction'] = recon

        out_path = os.path.join(output_dir, 'evaluation_metrics_singlefile.json')
        self.save_json_safe(results, out_path)
        return results


# -----------------------------------------------------------------------------
# Main entry point
# -----------------------------------------------------------------------------
def main():
    parser = argparse.ArgumentParser(description="Evaluate SELFIES generation (single-file version)")
    parser.add_argument('--generated', required=True,
                        help="Path to the generated results file (contains Generated_SELFIES, Generated_SMILES, Ground_Truth_SELFIES)")
    parser.add_argument('--train_file', required=False,
                        help="(Optional) Path to training dataset file (SELFIES or SMILES). If provided, novelty is measured vs training set.")
    parser.add_argument('--output_dir', default='./evaluation_results', help="Directory to save results")
    args = parser.parse_args()

    evaluator = MolecularEvaluatorSingleFile(args.generated, train_file=args.train_file)
    evaluator.run_evaluation(args.output_dir)


if __name__ == "__main__":
    main()
